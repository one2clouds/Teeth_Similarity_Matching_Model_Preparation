{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be434b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "import torch\n",
    "import open3d as o3d\n",
    "import json\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# mesh = trimesh.load(\"/home/shirshak/STL_client_data/11/2024-07-05_00003-InoueYui-11Cr-11-crown_cad.stl\")\n",
    "# mesh.show()\n",
    "import glob \n",
    "from tqdm import tqdm \n",
    "import time\n",
    "import os \n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456e573",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c5a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_point_cloud(file_path, num_points=2048):\n",
    "    \"\"\"Load and preprocess a single obj file into point cloud file.\"\"\"\n",
    "    mesh = o3d.io.read_triangle_mesh(file_path)\n",
    "    mesh.compute_vertex_normals()\n",
    "    o3d.utility.random.seed(12345)\n",
    "\n",
    "    pcd = mesh.sample_points_uniformly(number_of_points=num_points)\n",
    "\n",
    "    points = np.asarray(pcd.points, dtype=np.float32)\n",
    "\n",
    "    return torch.from_numpy(points)\n",
    "\n",
    "\n",
    "def mesh_to_voxel_grid(mesh, voxel_size=2):\n",
    "    \"\"\"Convert a mesh to a voxel grid using Open3D.\"\"\"\n",
    "    return o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=voxel_size)\n",
    "\n",
    "def load_voxel_grid(file_path, voxel_size=2):\n",
    "    \"\"\"Load and preprocess a single obj file into a voxel grid.\"\"\"\n",
    "    mesh = o3d.io.read_triangle_mesh(file_path)\n",
    "    return mesh_to_voxel_grid(mesh, voxel_size)\n",
    "\n",
    "def load_data_from_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for entry in data:\n",
    "        entry['feature_vector'] = np.array(entry['feature_vector'])\n",
    "    return data\n",
    "\n",
    "def compute_voxel_dice_score(voxel_grid1, voxel_grid2):\n",
    "    \"\"\"\n",
    "    Compute the Dice score between two voxel grids.\n",
    "    \"\"\"\n",
    "    # Get the set of voxel coordinates for each voxel grid\n",
    "    voxels1 = set([tuple(voxel.grid_index) for voxel in voxel_grid1.get_voxels()])\n",
    "    voxels2 = set([tuple(voxel.grid_index) for voxel in voxel_grid2.get_voxels()])\n",
    "    # Compute intersection of the voxel sets\n",
    "    intersection = voxels1.intersection(voxels2)\n",
    "    # Dice Score = 2 * |A âˆ© B| / (|A| + |B|)\n",
    "    dice_score = (2 * len(intersection)) / (len(voxels1) + len(voxels2)) if (len(voxels1) + len(voxels2)) > 0 else 0\n",
    "    return dice_score\n",
    "\n",
    "def get_similar_teeth_paths(pid, fid_and_similarity_score, base_path=\"\"):\n",
    "    \n",
    "    left_tooth_category = \"upper\" if int(fid_and_similarity_score[0][0].split(\"fid\")[-1]) < 30 else \"lower\"\n",
    "    right_tooth_category = \"upper\" if int(fid_and_similarity_score[1][0].split(\"fid\")[-1]) < 30 else \"lower\"\n",
    "    opposite_tooth_category = \"upper\" if int(fid_and_similarity_score[2][0].split(\"fid\")[-1]) < 30 else \"lower\"\n",
    "\n",
    "    left_similar_teeth = f\"{base_path}/{pid}_{left_tooth_category}_{fid_and_similarity_score[0][0]}.obj\"\n",
    "    right_similar_teeth = f\"{base_path}/{pid}_{right_tooth_category}_{fid_and_similarity_score[1][0]}.obj\"\n",
    "    opposite_similar_teeth = f\"{base_path}/{pid}_{opposite_tooth_category}_{fid_and_similarity_score[2][0]}.obj\"\n",
    "\n",
    "    similar_teeth_paths = [left_similar_teeth, right_similar_teeth, opposite_similar_teeth]\n",
    "\n",
    "    return similar_teeth_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18850ab8",
   "metadata": {},
   "source": [
    "# DGCNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate(x, xx):\n",
    "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
    "    torch.cuda.empty_cache()\n",
    "    return -xx - inner\n",
    "\n",
    "def knn(x, k):\n",
    "    x = x.to(torch.float16)\n",
    "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
    "    pairwise_distance = intermediate(x, xx) - xx.transpose(2, 1)\n",
    "    torch.cuda.empty_cache()\n",
    "    idx = pairwise_distance.topk(k=k, dim=-1)[1]\n",
    "    return idx\n",
    "\n",
    "def get_graph_feature(x, device, k=20, idx=None, dim9=False):\n",
    "    batch_size = x.size(0)\n",
    "    num_points = x.size(2)\n",
    "    x = x.view(batch_size, -1, num_points)\n",
    "    if idx is None:\n",
    "        if dim9 is False:\n",
    "            idx = knn(x, k=k)\n",
    "        else:\n",
    "            idx = knn(x[:, 6:], k=k)\n",
    "\n",
    "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
    "\n",
    "    idx = idx + idx_base\n",
    "    idx = idx.view(-1)\n",
    "\n",
    "    _, num_dims, _ = x.size()\n",
    "\n",
    "    x = x.transpose(2, 1).contiguous()\n",
    "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
    "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
    "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
    "    \n",
    "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
    "    return feature\n",
    "\n",
    "class DGCNN(nn.Module):\n",
    "    def __init__(self, device, output_channels=16,input_dims=3, k =20, emb_dims = 1024, dropout= 0.5):\n",
    "        super(DGCNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.input_dims = input_dims\n",
    "        self.k = k\n",
    "        self.emb_dims = emb_dims\n",
    "        self.dropout = dropout\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.bn5 = nn.BatchNorm1d(self.emb_dims)\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(self.input_dims*2, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn1,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn2,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
    "                                   self.bn3,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
    "                                   self.bn4,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv5 = nn.Sequential(nn.Conv1d(512, self.emb_dims, kernel_size=1, bias=False),\n",
    "                                   self.bn5,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.linear1 = nn.Linear(self.emb_dims*2, 512, bias=False)\n",
    "        self.bn6 = nn.BatchNorm1d(512)\n",
    "        self.dp1 = nn.Dropout(p=self.dropout)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.bn7 = nn.BatchNorm1d(256)\n",
    "        self.dp2 = nn.Dropout(p=self.dropout)\n",
    "        self.linear3 = nn.Linear(256, output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = get_graph_feature(x, k=self.k, device=self.device)      # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)\n",
    "        x = self.conv1(x)                       # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x1 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "\n",
    "        x = get_graph_feature(x1, k=self.k, device=self.device)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)\n",
    "        x = self.conv2(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)\n",
    "        x2 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)\n",
    "\n",
    "        x = get_graph_feature(x2, k=self.k, device=self.device)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)\n",
    "        x = self.conv3(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 128, num_points, k)\n",
    "        x3 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 128, num_points, k) -> (batch_size, 128, num_points)\n",
    "\n",
    "        x = get_graph_feature(x3, k=self.k, device=self.device)     # (batch_size, 128, num_points) -> (batch_size, 128*2, num_points, k)\n",
    "        x = self.conv4(x)                       # (batch_size, 128*2, num_points, k) -> (batch_size, 256, num_points, k)\n",
    "        x4 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 256, num_points, k) -> (batch_size, 256, num_points)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)  # (batch_size, 64+64+128+256, num_points)\n",
    "\n",
    "        x = self.conv5(x)                       # (batch_size, 64+64+128+256, num_points) -> (batch_size, emb_dims, num_points)\n",
    "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)           # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)\n",
    "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)           # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)\n",
    "        x = torch.cat((x1, x2), 1)              # (batch_size, emb_dims*2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2) # (batch_size, emb_dims*2) -> (batch_size, 512)\n",
    "        x = self.dp1(x)\n",
    "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2) # (batch_size, 512) -> (batch_size, 256)\n",
    "        x = self.dp2(x)\n",
    "        # x = self.linear3(x)                                             # (batch_size, 256) -> (batch_size, output_channels)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c7cc9",
   "metadata": {},
   "source": [
    "# Similarity Search Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114de67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilaritySearch:\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(0)\n",
    "        self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.load_model_and_checkpoint()\n",
    "        self.model.eval()\n",
    "\n",
    "    def load_model_and_checkpoint(self):\n",
    "        self.model = DGCNN(device=self.device, output_channels=32)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.checkpoint = torch.load(\"best_model.pth\")\n",
    "        self.model.load_state_dict(self.checkpoint[\"model_state_dict\"])\n",
    "        \n",
    "        self.model.dp1 = nn.Identity()\n",
    "        self.model.dp2 = nn.Identity()\n",
    "        self.model.linear3 = nn.Identity()\n",
    "\n",
    "    def find_top_n_similar_feature_vectors(self, query_vector, data, top_n=-1):\n",
    "        all_feature_vectors = np.array([entry['feature_vector'] for entry in data])\n",
    "        similarities = cosine_similarity(query_vector, all_feature_vectors).flatten()\n",
    "        if top_n != -1:\n",
    "            top_n_indices = np.argsort(-similarities)[:top_n]\n",
    "        else:\n",
    "            top_n_indices = np.argsort(-similarities)[:]\n",
    "        \n",
    "        similarities = [similarities[index] for index in top_n_indices]\n",
    "        return top_n_indices, similarities\n",
    "    \n",
    "    def get_pid_fid_from_indices(self, indices, data):\n",
    "        pids = []\n",
    "        fids = []\n",
    "        for idx in indices:\n",
    "            thumbnail_path = data[idx]['thumbnail_location']\n",
    "            pids.append(thumbnail_path.split('/')[-1].split('_')[0])\n",
    "            fids.append(thumbnail_path.split('/')[-1].split('.')[0].split('_')[-1])\n",
    "        return pids, fids\n",
    "    \n",
    "    def pack_json(self, pids, fids, similarity_score, dice_score):\n",
    "        ranked_data = [\n",
    "            {\n",
    "                'pid': pid,\n",
    "                'fid': fid,\n",
    "                'similarity_score': score,\n",
    "                'dice_score': dice\n",
    "            }\n",
    "            for pid, fid, score, dice in zip(pids, fids, similarity_score, dice_score)\n",
    "        ]\n",
    "\n",
    "        # Return the list of dictionaries, FastAPI will handle JSON serialization\n",
    "        return ranked_data\n",
    "    \n",
    "    def get_similarity(self, obj_path):\n",
    "        data_point_cloud_orig = load_point_cloud(obj_path)\n",
    "        data_point_cloud = data_point_cloud_orig.to(self.device).unsqueeze(0).permute(0,2,1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            original_feature_256 = self.model(data_point_cloud)\n",
    "\n",
    "        original_feature_256 = original_feature_256.cpu().numpy()\n",
    "\n",
    "        feature_data = load_data_from_json('feature_info.json')\n",
    "\n",
    "        top_10_indices, simil = self.find_top_n_similar_feature_vectors(original_feature_256, feature_data, top_n=-1)\n",
    "\n",
    "        pids, fids = self.get_pid_fid_from_indices(top_10_indices, feature_data)\n",
    "\n",
    "        return pids, fids, simil\n",
    "\n",
    "    # There might be some missing tooth as well, so we need to take that into account\n",
    "    def filter_ids_with_min_teeth(self, all_results, min_teeth=3):\n",
    "        filtered_results = {}\n",
    "        for id_code, teeth_data in all_results.items():\n",
    "            num_teeth = len(teeth_data) if hasattr(teeth_data, '__len__') else 0\n",
    "            # Only keep IDs with at least min_teeth\n",
    "            if num_teeth >= min_teeth:\n",
    "                filtered_results[id_code] = teeth_data\n",
    "        return filtered_results\n",
    "\n",
    "    def get_dice(self, all_results, teeth_paths, pid):\n",
    "        dice_scores = []\n",
    "        dice_scores_dict = {}\n",
    "\n",
    "        for row, teeth_path in zip(all_results[pid], teeth_paths):\n",
    "            if int(row[0].split(\"fid\")[-1]) < 30:\n",
    "                category = 'upper'\n",
    "            if int(row[0].split(\"fid\")[-1]) > 30:\n",
    "                category = 'lower'\n",
    "\n",
    "            sim_obj_path = f\"/home/shirshak/Teeth3DS_individual_teeth/individual_teeth/{pid}_{category}_{row[0]}.obj\"\n",
    "\n",
    "            orig_mesh = load_voxel_grid(teeth_path)\n",
    "            similar_mesh = load_voxel_grid(sim_obj_path)\n",
    "\n",
    "            dice_score = compute_voxel_dice_score(orig_mesh, similar_mesh)\n",
    "\n",
    "            dice_scores.append(dice_score)\n",
    "\n",
    "            dice_scores_dict[sim_obj_path] = dice_score\n",
    "\n",
    "        return dice_scores_dict, dice_scores, float(np.array(dice_scores).mean())\n",
    "\n",
    "    def get_tooth_path(self, indiv_tooth_fid_with_similarity, pid):\n",
    "        if int(indiv_tooth_fid_with_similarity[0].split(\"fid\")[-1]) < 30:\n",
    "            category = 'upper'\n",
    "        else:\n",
    "            category = 'lower'\n",
    "        tooth_path = f\"/home/shirshak/Teeth3DS_individual_teeth/individual_teeth/{pid}_{category}_{indiv_tooth_fid_with_similarity[0]}.obj\"\n",
    "        return tooth_path\n",
    "    \n",
    "\n",
    "    def get_similarity_multiple_teeth(self, teeth_paths, tooth_labels):\n",
    "        if len(teeth_paths) != len(tooth_labels):\n",
    "            raise ValueError(\"Number of tooth paths must match number of tooth labels\")\n",
    "        \n",
    "        # Similarity for each tooth\n",
    "        all_results = {}\n",
    "        for tooth_path, tooth_label in tqdm(zip(teeth_paths, tooth_labels)):\n",
    "            pids, fids, similarity_scores = self.get_similarity(tooth_path)\n",
    "\n",
    "            for pid, fid, similarity_score in zip(pids, fids, similarity_scores):\n",
    "                # print(pid)\n",
    "                # print(fid)\n",
    "                fid_number = int(fid.split(\"fid\")[-1])\n",
    "\n",
    "                if fid_number == tooth_label: # because fid ====> fid32, so to only extract 32\n",
    "                    if pid in all_results:\n",
    "                        all_results[pid].append([fid, similarity_score])\n",
    "                    else:\n",
    "                        all_results[pid] = [[fid, similarity_score]]\n",
    "        \n",
    "        # print(all_results)\n",
    "\n",
    "        avg_similarity_score = {}\n",
    "        for result_key in all_results.keys():\n",
    "            avg_similarity_score[result_key] = sum(item[1] for item in all_results[result_key]) / len(all_results[result_key])\n",
    "\n",
    "        # Sort the avg_similarity score\n",
    "        avg_similarity_score = sorted(avg_similarity_score.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        avg_dice_score = {}\n",
    "        top_10_similar_embeddings = 10\n",
    "        for i in range(top_10_similar_embeddings):\n",
    "            pid = avg_similarity_score[i][0]\n",
    "            # print(self.get_dice(all_results, teeth_paths, pid))\n",
    "            _, _, total_dice = self.get_dice(all_results, teeth_paths, pid)\n",
    "            avg_dice_score[pid] = total_dice\n",
    "\n",
    "        # Sort the avg dice score\n",
    "        avg_dice_score = sorted(avg_dice_score.items(), key=lambda item: item[1], reverse=True)\n",
    "        print(avg_dice_score)\n",
    "\n",
    "        pid = avg_dice_score[2][0] # Gives PID For 2nd position, as most similar on 2nd position tooth\n",
    "        avg_dice_score = avg_dice_score[2][1] # Gives PID For 2nd position, as most similar on 1st position tooth\n",
    "\n",
    "        # print(\"-----------------------------------\")\n",
    "        # print(self.get_dice(all_results, teeth_paths, pid))\n",
    "        dice_scores_dict, dice_scores, _ = self.get_dice(all_results, teeth_paths, pid)\n",
    "\n",
    "        # print(dice_scores_dict.items())\n",
    "        # print(dice_scores)\n",
    "\n",
    "        return pid, all_results[pid], {\"dice_scores_dict\":dice_scores_dict, \"avg_dice_score\":avg_dice_score}, \n",
    "\n",
    "\n",
    "    def get_similar_crowns(self, tooth_obj_path, label_damaged):\n",
    "        data_point_cloud_orig = load_point_cloud(tooth_obj_path, num_points=2048)\n",
    "        data_point_cloud = data_point_cloud_orig.transpose(0, 1).unsqueeze(0).to(self.device)\n",
    "        # print(data_point_cloud.shape)\n",
    "        orig_mesh = load_voxel_grid(tooth_obj_path)\n",
    "        # print(data_point_cloud.shape)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            original_feature_256 = self.model(data_point_cloud)\n",
    "\n",
    "        original_feature_256 = original_feature_256.cpu().numpy()\n",
    "        feature_data = load_data_from_json('feature_info_client_data.json')\n",
    "\n",
    "        new_feature_data = self.get_feature_data_of_selected_label_only(feature_data, label_damaged)\n",
    "\n",
    "        top_10_indices, simil = self.find_top_n_similar_feature_vectors(original_feature_256, new_feature_data, top_n=-1)\n",
    "\n",
    "        # print(len(top_10_indices))\n",
    "        # print(feature_data)\n",
    "        final_scores = {}\n",
    "        for index, similarity in zip(top_10_indices, simil):\n",
    "            sim_obj_path = new_feature_data[index]['mesh_location']\n",
    "            # print(sim_obj_path)\n",
    "\n",
    "            similar_mesh = load_voxel_grid(sim_obj_path)\n",
    "            dice_score = compute_voxel_dice_score(orig_mesh, similar_mesh)\n",
    "            final_scores[sim_obj_path] =[f\"Similarity Score : {similarity}\", f\"Dice Score : {dice_score}\"]\n",
    "        # Sort the final scores according to the dice_scores \n",
    "        sorted_final_scores = dict(sorted(final_scores.items(), key=lambda item: item[1][1], reverse=True))\n",
    "        # print(sorted_final_scores)\n",
    "        return sorted_final_scores\n",
    "\n",
    "    def get_feature_data_of_selected_label_only(self, feature_data, label_damaged):\n",
    "        data_json = []\n",
    "        # print(len(feature_data))\n",
    "        for i in range(len(feature_data)):\n",
    "            # print(feature_data[i]['label'])\n",
    "            if int(feature_data[i]['label']) == int(label_damaged):\n",
    "                data_json.append({\n",
    "                \"mesh_location\": feature_data[i]['mesh_location'],\n",
    "                \"label\": feature_data[i]['label'], \n",
    "                \"feature_vector\": feature_data[i]['feature_vector']\n",
    "                })\n",
    "        # print(data_json)\n",
    "        return data_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e5957",
   "metadata": {},
   "source": [
    "# Extract Individual Teeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fids_lower = [31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48]\n",
    "fids_upper = [11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "\n",
    "def extract_teeth(indir, outdir):\n",
    "    # print(\"Out Dir\")\n",
    "    # print(outdir)\n",
    "\n",
    "    json_file_paths = sorted(glob.glob(indir + \"*.json\"))\n",
    "    mesh_paths = sorted(glob.glob(indir + \"*.obj\"))\n",
    "    \n",
    "\n",
    "    for (json_file_path, mesh_path) in zip(json_file_paths, mesh_paths):\n",
    "        print(json_file_path)\n",
    "        print(mesh_path)\n",
    "        \n",
    "        base_mesh_name = mesh_path.split(\"/\")[-1]\n",
    "        base_mesh_name = base_mesh_name.replace(\".obj\", \"\")\n",
    "        \n",
    "        with open(json_file_path) as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "\n",
    "        face_labels = [json_data[\"cells\"][i][\"fdi\"] for i in range(len(json_data[\"cells\"]))]\n",
    "        face_labels = np.array(face_labels)\n",
    "\n",
    "        with open(mesh_path) as obj_file:\n",
    "            obj_lines = obj_file.readlines()\n",
    "\n",
    "        v_start = 0\n",
    "        while v_start < len(obj_lines) and not obj_lines[v_start].startswith(\"v \"):\n",
    "            v_start += 1\n",
    "        \n",
    "        f_start = v_start\n",
    "        while f_start < len(obj_lines) and not obj_lines[f_start].startswith(\"f \"):\n",
    "            f_start += 1\n",
    "\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "\n",
    "        if \"lower\"  in base_mesh_name.lower() or \"preparation\" in base_mesh_name.lower():\n",
    "            fids_selection = fids_lower\n",
    "        elif \"upper\"  in base_mesh_name.lower() or \"antagonist\" in base_mesh_name.lower():\n",
    "            fids_selection = fids_upper\n",
    "\n",
    "        for teeth_no in fids_selection:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            faces_to_extract = np.where(face_labels == teeth_no)[0]\n",
    "            \n",
    "            if len(faces_to_extract) == 0:\n",
    "                continue\n",
    "            \n",
    "            vertices_to_extract = set()\n",
    "            valid_faces = []\n",
    "            \n",
    "            for face_idx in faces_to_extract:\n",
    "                if f_start + face_idx >= len(obj_lines):\n",
    "                    continue\n",
    "                    \n",
    "                face_line = obj_lines[f_start + face_idx].strip()\n",
    "                if not face_line.startswith(\"f \"):\n",
    "                    continue\n",
    "                    \n",
    "                parts = face_line.split()\n",
    "                if len(parts) < 4:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    v1 = int(parts[1].split('/')[0]) - 1\n",
    "                    v2 = int(parts[2].split('/')[0]) - 1  \n",
    "                    v3 = int(parts[3].split('/')[0]) - 1\n",
    "                    \n",
    "                    vertices_to_extract.add(v1)\n",
    "                    vertices_to_extract.add(v2)\n",
    "                    vertices_to_extract.add(v3)\n",
    "                    valid_faces.append((v1, v2, v3))\n",
    "                    \n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "            \n",
    "            if len(vertices_to_extract) == 0:\n",
    "                print(f\"No valid vertices found for tooth {teeth_no}\")\n",
    "                continue\n",
    "                \n",
    "            vertices_to_extract = sorted(list(vertices_to_extract))\n",
    "            vertex_mapping = {old_idx: new_idx + 1 for new_idx, old_idx in enumerate(vertices_to_extract)}\n",
    "            \n",
    "            output_path = os.path.join(outdir, f\"{base_mesh_name}_fid{teeth_no-1}.obj\") # TODO REMOVE THE -1 TERM FROM TEETH_NO. NOW WE'RE JUST USING IT BECAUSE TEETH 3DS DOESN'T HAVE LABEL 48 TOOTH SO......\n",
    "            \n",
    "            with open(output_path, \"w\") as new_obj_file:\n",
    "                for vertex_idx in vertices_to_extract:\n",
    "                    if v_start + vertex_idx < len(obj_lines):\n",
    "                        vertex_line = obj_lines[v_start + vertex_idx]\n",
    "                        if vertex_line.startswith(\"v \"):\n",
    "                            new_obj_file.write(vertex_line)\n",
    "                \n",
    "                for v1, v2, v3 in valid_faces:\n",
    "                    if v1 in vertex_mapping and v2 in vertex_mapping and v3 in vertex_mapping:\n",
    "                        new_v1 = vertex_mapping[v1]\n",
    "                        new_v2 = vertex_mapping[v2]\n",
    "                        new_v3 = vertex_mapping[v3]\n",
    "                        new_obj_file.write(f\"f {new_v1} {new_v2} {new_v3}\\n\")\n",
    "                    \n",
    "            end_time = time.time()\n",
    "            print(f\"Time taken for extracting tooth {teeth_no} from {indir}: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "            print(output_path)\n",
    "        \n",
    "        \n",
    "def read_ply_file(ply_path):\n",
    "    \"\"\"\n",
    "    Read PLY file and preserve vertex ordering\n",
    "    \"\"\"\n",
    "    mesh = o3d.io.read_triangle_mesh(ply_path)\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    faces = np.asarray(mesh.triangles) + 1\n",
    "    \n",
    "    if mesh.has_vertex_colors():\n",
    "        rgb = np.asarray(mesh.vertex_colors)\n",
    "    else:\n",
    "        rgb = np.full((len(vertices), 3), 0.501)\n",
    "    \n",
    "    print(f\"Read PLY file: {len(vertices)} vertices, {len(faces)} faces\")\n",
    "    return vertices, rgb, faces\n",
    "\n",
    "def convert_ply_to_obj(ply_path):\n",
    "    \"\"\"\n",
    "    Convert PLY to OBJ format while preserving vertex order\n",
    "    \"\"\"\n",
    "    vertices, rgb, faces = read_ply_file(ply_path)\n",
    "    vertex_count = len(vertices)\n",
    "\n",
    "    obj_path = Path(ply_path).with_suffix(\".obj\")\n",
    "\n",
    "    with open(obj_path, 'w') as f:\n",
    "        for v, c in zip(vertices, rgb):\n",
    "            f.write(f\"v {v[0]} {v[1]} {v[2]} {c[0]} {c[1]} {c[2]}\\n\")\n",
    "        for face in faces:\n",
    "            f.write(f\"f {face[0]} {face[1]} {face[2]}\\n\")\n",
    "    \n",
    "    return obj_path, vertex_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b6962",
   "metadata": {},
   "source": [
    "# Taking a jaw scan of patient in ply and conversion of it in obj : lower_jaw_1.ply => lower_jaw_1.obj  & upper_jaw_1.ply => upper_jaw_1.obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83751c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _ = convert_ply_to_obj(\"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA/pdf_2c_20220629_084758_ITERO(100008941)_0/pdf_2c_20220629_084758_ITERO(100008941)_0-AntagonistScan.ply\")\n",
    "# _, _ = convert_ply_to_obj(\"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA/pdf_2c_20220629_084758_ITERO(100008941)_0/pdf_2c_20220629_084758_ITERO(100008941)_0-PreparationScan.ply\")\n",
    "\n",
    "_, _ = convert_ply_to_obj(\"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA_2/JAW_1234565/lower_jaw_1.ply\")\n",
    "_, _ = convert_ply_to_obj(\"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA_2/JAW_1234565/upper_jaw_1.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6548b",
   "metadata": {},
   "source": [
    "# Extraction of each individual teeth of the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74367633",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_folder_paths = glob.glob(\"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA_2/JAW_1234565/\")      #input path of the original raw data\n",
    "outdir = \"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA_2/JAW_1234565/individual_teeth/\"       #output folder of the indivial teeth\n",
    "\n",
    "\n",
    "for mesh_folder_path in mesh_folder_paths:\n",
    "    # print(mesh_folder_path)\n",
    "    patient_id = mesh_folder_path.split(\"/\")[-2]\n",
    "    # print(patient_id)\n",
    "    start_time = time.time()\n",
    "    extract_teeth(mesh_folder_path, os.path.join(outdir))\n",
    "    # extract_teeth(mesh_folder_path, os.path.join(outdir + patient_id))\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n Time taken for extracting all tooth from IOS: {patient_id}: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tooth = 47\n",
    "damaged_tooth = 46\n",
    "right_tooth = 45\n",
    "opposite_tooth = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ab9f6",
   "metadata": {},
   "source": [
    "# Visualize Client Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_name_2 = \"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA_2/JAW_1234565/lower_jaw_1.ply\"\n",
    "mesh_name_1 = \"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA_2/JAW_1234565/upper_jaw_1.ply\"\n",
    "\n",
    "mesh1 = o3d.io.read_triangle_mesh(mesh_name_1)\n",
    "mesh2 = o3d.io.read_triangle_mesh(mesh_name_2)\n",
    "\n",
    "# center_m1 = mesh1.get_center()\n",
    "# mesh1.translate(-center_m1)\n",
    "\n",
    "# center_m2 = mesh2.get_center()\n",
    "# mesh2.translate(-center_m2)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'<h1>Client Data : Damaged Jaw Visualization</h1>'))\n",
    "\n",
    "# o3d.visualization.draw_plotly([mesh1])\n",
    "# o3d.visualization.draw_plotly([mesh2])\n",
    "\n",
    "# Combine both meshes in single plot\n",
    "# mesh2 = mesh2.translate([20, 0, -10])\n",
    "\n",
    "print(f\"Jaw with one smaller tooth (Abutment Tooth) ==> Lower Jaw : {os.path.basename(mesh_name_1)}\")\n",
    "print(f\"Teeth without abutment tooth ==> Upper Jaw : {os.path.basename(mesh_name_2)}\")\n",
    "print(f\"Abutment tooth FDI Number : {damaged_tooth}\")\n",
    "\n",
    "\n",
    "# o3d.visualization.draw_plotly([mesh1])\n",
    "# o3d.visualization.draw_plotly([mesh2])\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a04a1a",
   "metadata": {},
   "source": [
    "#### For damaged tooth 46, select its left (47) and right (45) adjacent tooth, and opposite tooth (16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaeb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tooth = 47\n",
    "damaged_tooth = 46\n",
    "right_tooth = 45\n",
    "opposite_tooth = 16\n",
    "\n",
    "\n",
    "left_tooth_path, right_tooth_path, opposite_tooth_path = \"\", \"\", \"\"\n",
    "\n",
    "\n",
    "for file_name in sorted(glob.glob(\"/home/shirshak/00_teeth_similarity_matching/CLIENT_DATA_2/JAW_1234565/individual_teeth/*\")):\n",
    "\n",
    "    label = int(file_name.split(\"/\")[-1].split(\".obj\")[0].split(\"fid\")[-1])\n",
    "\n",
    "    if label == left_tooth:\n",
    "        left_tooth_path = file_name\n",
    "    \n",
    "    if  label == right_tooth:\n",
    "        right_tooth_path = file_name\n",
    "\n",
    "    if label == opposite_tooth:\n",
    "        opposite_tooth_path = file_name\n",
    "\n",
    "assert left_tooth_path != \"\" and right_tooth_path != \"\" and opposite_tooth_path != \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "teeth_paths = [left_tooth_path, right_tooth_path, opposite_tooth_path]\n",
    "tooth_labels = [left_tooth, right_tooth, opposite_tooth]\n",
    "\n",
    "teeth_paths, tooth_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255efe5",
   "metadata": {},
   "source": [
    "# Similarity search algorithm to extract most similar jaw of teeth3ds database of 900 jaws from left, right, opposite adjacent teeth of abutment teeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7622f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_search = SimilaritySearch()\n",
    "pid, fid_and_similarity_score, dice_dict =  similarity_search.get_similarity_multiple_teeth(teeth_paths, tooth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_individual_dict = dice_dict[\"dice_scores_dict\"]\n",
    "dice_avg_score = dice_dict[\"avg_dice_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tooth_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dice_scores = {}\n",
    "\n",
    "for path, dice_score in dice_individual_dict.items():\n",
    "    jaw_name = os.path.basename(path).split(\".obj\")[0]\n",
    "    fid_num = os.path.basename(path).split(\".obj\")[0].split(\"fid\")[1]\n",
    "\n",
    "    if int(fid_num) == int(tooth_labels[0]):\n",
    "        final_dice_scores[\"left_dice\"] = dice_score\n",
    "    \n",
    "    elif int(fid_num) == int(tooth_labels[1]):\n",
    "        final_dice_scores[\"right_dice\"] = dice_score\n",
    "\n",
    "    elif int(fid_num) == int(tooth_labels[2]):\n",
    "        final_dice_scores[\"opposite_dice\"] = dice_score\n",
    "\n",
    "    final_dice_scores[\"jaw_name\"] = jaw_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dice_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88137214",
   "metadata": {},
   "source": [
    "##### From above we see, the same jaw AD8EQEUR is the most similar tooth. Now extraction of each of similar tooth parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_teeth_paths = get_similar_teeth_paths(pid, fid_and_similarity_score, base_path=\"/home/shirshak/Teeth3DS_individual_teeth/individual_teeth\")\n",
    "similar_teeth_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh1 = o3d.io.read_triangle_mesh(teeth_paths[0])\n",
    "# mesh2 = o3d.io.read_triangle_mesh(similar_teeth_paths[0])\n",
    "\n",
    "# mesh2 = mesh2.translate([13, 0, 0])\n",
    "\n",
    "# o3d.visualization.draw_plotly([mesh1, mesh2], window_name=\"Given Tooth VS Similar Tooth\", mesh_show_wireframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d540c",
   "metadata": {},
   "source": [
    "# Visualize most similar right, left and opposite tooth from Teeth3DS Database of 900 jaw scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27031241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_orientation(mesh_to_align, reference_mesh):\n",
    "    \"\"\"\n",
    "    Align the orientation of mesh_to_align to match reference_mesh using PCA.\n",
    "    \n",
    "    Args:\n",
    "        mesh_to_align: The mesh whose orientation needs to be changed\n",
    "        reference_mesh: The reference mesh to align to\n",
    "    \n",
    "    Returns:\n",
    "        Aligned mesh (copy of mesh_to_align with corrected orientation)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create copies to avoid modifying original meshes\n",
    "    mesh_copy = o3d.geometry.TriangleMesh(mesh_to_align)\n",
    "    \n",
    "    # Get vertices as numpy arrays\n",
    "    vertices_to_align = np.asarray(mesh_copy.vertices)\n",
    "    vertices_reference = np.asarray(reference_mesh.vertices)\n",
    "    \n",
    "    # Perform PCA on both meshes to find principal components\n",
    "    pca_to_align = PCA(n_components=3)\n",
    "    pca_reference = PCA(n_components=3)\n",
    "    \n",
    "    pca_to_align.fit(vertices_to_align)\n",
    "    pca_reference.fit(vertices_reference)\n",
    "    \n",
    "    # Get the principal component matrices (rotation matrices)\n",
    "    components_to_align = pca_to_align.components_\n",
    "    components_reference = pca_reference.components_\n",
    "    \n",
    "    # Ensure consistent orientation of principal components\n",
    "    # Flip components if they point in opposite directions\n",
    "    for i in range(3):\n",
    "        if np.dot(components_to_align[i], components_reference[i]) < 0:\n",
    "            components_to_align[i] *= -1\n",
    "    \n",
    "    # Calculate rotation matrix to align principal components\n",
    "    # R = R_ref * R_to_align^T\n",
    "    rotation_matrix = components_reference.T @ components_to_align\n",
    "    \n",
    "    # Apply rotation to the mesh\n",
    "    mesh_copy.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "    \n",
    "    return mesh_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_meshes(teeth_path, similar_teeth_path, which_tooth = \"\", dice_score = 0, rotation_degree = None):\n",
    "    mesh1 = o3d.io.read_triangle_mesh(teeth_path)\n",
    "    mesh2 = o3d.io.read_triangle_mesh(similar_teeth_path)\n",
    "\n",
    "    center_m1 = mesh1.get_center()\n",
    "    mesh1.translate(-center_m1)\n",
    "\n",
    "    center_m2 = mesh2.get_center()\n",
    "    mesh2.translate(-center_m2)\n",
    "\n",
    "    mesh2 = align_orientation(mesh2, mesh1)\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(f'<h1>{which_tooth} Most Similar</h1>'))\n",
    "    # o3d.visualization.draw_plotly([mesh1])\n",
    "    # o3d.visualization.draw_plotly([mesh2])\n",
    "\n",
    "    # Combine both meshes in single plot\n",
    "    mesh2 = mesh2.translate([15, 0, 0])\n",
    "\n",
    "    print(f\"Left ==> Original Tooth : {os.path.basename(teeth_path)}\")\n",
    "    print(f\"Right ==> Most Similar Tooth : {os.path.basename(similar_teeth_path)}\")\n",
    "    print(f\"Dice Score = {dice_score}\")\n",
    "\n",
    "    return mesh1, mesh2\n",
    "\n",
    "    # o3d.visualization.draw_plotly([mesh1, mesh2])\n",
    "\n",
    "    # o3d.visualization.draw_plotly([mesh1])\n",
    "    # o3d.visualization.draw_plotly([mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78878e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_tooth = \"Left Tooth\"\n",
    "dice_score = final_dice_scores[\"left_dice\"]\n",
    "mesh1, mesh2 = transform_meshes(teeth_paths[0], similar_teeth_paths[0], which_tooth, dice_score)\n",
    "\n",
    "rotation_degree = 180\n",
    "rotation_matrix = mesh2.get_rotation_matrix_from_axis_angle([0, 0, np.radians(rotation_degree)])\n",
    "mesh2.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "\n",
    "rotation_matrix = mesh1.get_rotation_matrix_from_axis_angle([np.radians(47), 0, 0])\n",
    "mesh1.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_tooth = \"Right Tooth\"\n",
    "dice_score = final_dice_scores[\"right_dice\"]\n",
    "mesh1, mesh2 = transform_meshes(teeth_paths[1], similar_teeth_paths[1], which_tooth, dice_score)\n",
    "\n",
    "\n",
    "rotation_matrix = mesh2.get_rotation_matrix_from_axis_angle([np.radians(15), np.radians(0), np.radians(5)])\n",
    "mesh2.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "\n",
    "rotation_matrix = mesh1.get_rotation_matrix_from_axis_angle([np.radians(90), np.radians(55), np.radians(-15)])\n",
    "mesh1.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_tooth = \"Opposite Tooth\"\n",
    "dice_score = final_dice_scores[\"opposite_dice\"]\n",
    "mesh1, mesh2 = transform_meshes(teeth_paths[2], similar_teeth_paths[2], which_tooth, dice_score)\n",
    "\n",
    "rotation_matrix = mesh2.get_rotation_matrix_from_axis_angle([np.radians(0), np.radians(0), np.radians(180)])\n",
    "mesh2.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "\n",
    "rotation_matrix = mesh1.get_rotation_matrix_from_axis_angle([np.radians(0), np.radians(0), np.radians(180)])\n",
    "mesh1.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6e53b",
   "metadata": {},
   "source": [
    "# Visualize Teeth3DS most similar jaw with Client jaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea077fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh1 = o3d.io.read_triangle_mesh(\"AD8EQEUR_lower.obj\")\n",
    "mesh2 = o3d.io.read_triangle_mesh(\"AD8EQEUR_upper.obj\")\n",
    "\n",
    "rotation_matrix = mesh2.get_rotation_matrix_from_axis_angle([np.radians(180), np.radians(0), np.radians(0)])\n",
    "mesh2.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "\n",
    "\n",
    "rotation_matrix = mesh1.get_rotation_matrix_from_axis_angle([np.radians(0), np.radians(0), np.radians(180)])\n",
    "mesh1.rotate(rotation_matrix, center=(0, 0, 0))\n",
    "\n",
    "mesh2.translate([0, 0, -100])  # move UPPER jaw down\n",
    "mesh1.translate([0, 0, 57])  # move LOWER jaw up\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'''<h1> Most Similar Jaw : {os.path.basename(\"AD8EQEUR_lower.obj\").split(\"_\")[0]} </h1>'''))\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d02e59",
   "metadata": {},
   "source": [
    "# Visualize Teeth3DS most similar jaw's FID tooth (same FID as abutment tooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4044af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh = similar_teeth_paths[0].split(\".obj\")[0].split(\"fid\")[1]\n",
    "new_path = re.sub(r'fid\\d+', f'fid{damaged_tooth}', similar_teeth_paths[0])\n",
    "\n",
    "mesh = o3d.io.read_triangle_mesh(new_path)\n",
    "\n",
    "center_m = mesh.get_center()\n",
    "mesh.translate(-center_m)\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'''\n",
    "             <h1> Most Similar Jaw : {os.path.basename(new_path).split(\"_\")[0]}</h1>\n",
    "             <h1> Tooth FID : {os.path.basename(new_path).split(\".obj\")[0].split(\"fid\")[1]} </h1>\n",
    "             '''))\n",
    "print(f\"Teeth 3DS most similar jaw's FID Tooth : {os.path.basename(new_path)}\")\n",
    "print(f\"It is tooth whose Most Similar Crown to be extracted\")\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54943df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66d59f2c",
   "metadata": {},
   "source": [
    "# Find the most similar crown and its visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ce59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_file)\n",
    "if damaged_tooth < 30:\n",
    "    category = 'upper'\n",
    "else:\n",
    "    category = 'lower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"/home/shirshak/Teeth3DS_individual_teeth/individual_teeth/{pid}_{category}_fid{damaged_tooth}.obj\"\n",
    "final_crown_templates = similarity_search.get_similar_crowns(output_file, label_damaged=damaged_tooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_holder = {}\n",
    "json_holder[\"Most Similar Jaw's Abutment Tooth Filename :\"] = output_file\n",
    "\n",
    "for i in range(len(final_crown_templates)): \n",
    "    file_i = list(final_crown_templates.items())[i]\n",
    "    json_holder[f\"{i} Similar\"] = file_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_meshes(teeth_path, similar_teeth_path, which_tooth = \"\", dice_score = 0, rotation_degree = None):\n",
    "    mesh1 = o3d.io.read_triangle_mesh(teeth_path)\n",
    "    mesh2 = o3d.io.read_triangle_mesh(similar_teeth_path)\n",
    "\n",
    "    center_m1 = mesh1.get_center()\n",
    "    mesh1.translate(-center_m1)\n",
    "\n",
    "    center_m2 = mesh2.get_center()\n",
    "    mesh2.translate(-center_m2)\n",
    "\n",
    "    mesh2 = align_orientation(mesh2, mesh1)\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(f'<h1>{which_tooth} Most Similar</h1>'))\n",
    "    # o3d.visualization.draw_plotly([mesh1])\n",
    "    # o3d.visualization.draw_plotly([mesh2])\n",
    "\n",
    "    # Combine both meshes in single plot\n",
    "    mesh2 = mesh2.translate([15, 0, 0])\n",
    "\n",
    "    print(f\"Left ==> Original Tooth : {os.path.basename(teeth_path)}\")\n",
    "    print(f\"Right ==> Most Similar Tooth : {os.path.basename(similar_teeth_path)}\")\n",
    "    print(f\"Dice Score = {dice_score}\")\n",
    "\n",
    "    return mesh1, mesh2\n",
    "\n",
    "    # o3d.visualization.draw_plotly([mesh1, mesh2])\n",
    "\n",
    "    # o3d.visualization.draw_plotly([mesh1])\n",
    "    # o3d.visualization.draw_plotly([mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_most_similar_crown(abutment_teeth_most_similar_jaw_filename, most_similar_crown):\n",
    "    mesh1 = o3d.io.read_triangle_mesh(abutment_teeth_most_similar_jaw_filename)\n",
    "    mesh2 = o3d.io.read_triangle_mesh(most_similar_crown)\n",
    "\n",
    "    center_m1 = mesh1.get_center()\n",
    "    mesh1.translate(-center_m1)\n",
    "\n",
    "    center_m2 = mesh2.get_center()\n",
    "    mesh2.translate(-center_m2)\n",
    "\n",
    "    mesh2 = mesh2.translate([15, 0, 0])\n",
    "\n",
    "    return mesh1, mesh2 \n",
    "    # o3d.visualization.draw_plotly([mesh1])\n",
    "    # o3d.visualization.draw_plotly([mesh2])\n",
    "    # o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abutment_teeth_most_similar_jaw_filename = json_holder[\"Most Similar Jaw's Abutment Tooth Filename :\"]\n",
    "most_similar_crown = json_holder[\"0 Similar\"][0]\n",
    "\n",
    "similarity_score = json_holder[\"0 Similar\"][1][0]\n",
    "dice_score = json_holder[\"0 Similar\"][1][1]\n",
    "\n",
    "mesh1, mesh2 = compare_most_similar_crown(abutment_teeth_most_similar_jaw_filename, most_similar_crown)\n",
    "mesh1.translate([0, 0, 1.5])\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'<h1>Most Similar Crown</h1>'))\n",
    "\n",
    "print(f\"Left ==> Most Similar Crown : {os.path.basename(most_similar_crown)}\")\n",
    "print(f\"Right ==> Teeth3DS Similar Jaw's Tooth of same FDI Label as abutment : {os.path.basename(abutment_teeth_most_similar_jaw_filename)}\")\n",
    "print(dice_score)\n",
    "print(similarity_score)\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f166c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "abutment_teeth_most_similar_jaw_filename = json_holder[\"Most Similar Jaw's Abutment Tooth Filename :\"]\n",
    "most_similar_crown = json_holder[\"1 Similar\"][0]\n",
    "\n",
    "similarity_score = json_holder[\"1 Similar\"][1][0]\n",
    "dice_score = json_holder[\"1 Similar\"][1][1]\n",
    "\n",
    "mesh1, mesh2 = compare_most_similar_crown(abutment_teeth_most_similar_jaw_filename, most_similar_crown)\n",
    "\n",
    "# mesh1.translate([0, 0, 1.5])\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'<h1>2nd Most Similar Crown</h1>'))\n",
    "\n",
    "print(f\"Left ==> 2nd Most Similar Crown : {os.path.basename(most_similar_crown)}\")\n",
    "print(f\"Right ==> Teeth3DS Similar Jaw's Tooth of same FDI Label as abutment: {os.path.basename(abutment_teeth_most_similar_jaw_filename)}\")\n",
    "\n",
    "print(dice_score)\n",
    "print(similarity_score)\n",
    "\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cda3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "abutment_teeth_most_similar_jaw_filename = json_holder[\"Most Similar Jaw's Abutment Tooth Filename :\"]\n",
    "most_similar_crown = json_holder[\"1 Similar\"][0]\n",
    "\n",
    "similarity_score = json_holder[\"1 Similar\"][1][0]\n",
    "dice_score = json_holder[\"1 Similar\"][1][1]\n",
    "\n",
    "mesh1, mesh2 = compare_most_similar_crown(abutment_teeth_most_similar_jaw_filename, most_similar_crown)\n",
    "\n",
    "# mesh1.translate([0, 0, 1.5])\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'<h1>2nd Most Similar Crown</h1>'))\n",
    "\n",
    "print(f\"Left ==> 2nd Most Similar Crown : {os.path.basename(most_similar_crown)}\")\n",
    "print(f\"Right ==> Teeth3DS Similar Jaw's Tooth of same FDI Label as abutment: {os.path.basename(abutment_teeth_most_similar_jaw_filename)}\")\n",
    "\n",
    "print(dice_score)\n",
    "print(similarity_score)\n",
    "\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "abutment_teeth_most_similar_jaw_filename = json_holder[\"Most Similar Jaw's Abutment Tooth Filename :\"]\n",
    "most_similar_crown = json_holder[\"2 Similar\"][0]\n",
    "\n",
    "similarity_score = json_holder[\"2 Similar\"][1][0]\n",
    "dice_score = json_holder[\"2 Similar\"][1][1]\n",
    "\n",
    "mesh1, mesh2 = compare_most_similar_crown(abutment_teeth_most_similar_jaw_filename, most_similar_crown)\n",
    "\n",
    "# mesh1.translate([0, 0, 1.5])\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'<h1>3rd Most Similar Crown</h1>'))\n",
    "\n",
    "print(f\"Left ==> 3rd Most Similar Crown : {os.path.basename(most_similar_crown)}\")\n",
    "print(f\"Right ==> Teeth3DS Similar Jaw's Tooth of same FDI Label as abutment: {os.path.basename(abutment_teeth_most_similar_jaw_filename)}\")\n",
    "\n",
    "print(dice_score)\n",
    "print(similarity_score)\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abutment_teeth_most_similar_jaw_filename = json_holder[\"Most Similar Jaw's Abutment Tooth Filename :\"]\n",
    "most_similar_crown = json_holder[\"3 Similar\"][0]\n",
    "\n",
    "similarity_score = json_holder[\"3 Similar\"][1][0]\n",
    "dice_score = json_holder[\"3 Similar\"][1][1]\n",
    "\n",
    "mesh1, mesh2 = compare_most_similar_crown(abutment_teeth_most_similar_jaw_filename, most_similar_crown)\n",
    "\n",
    "# mesh1.translate([0, 0, 1.5])\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(f'<h1>4th Most Similar Crown</h1>'))\n",
    "\n",
    "print(f\"Left ==> 4th Most Similar Crown : {os.path.basename(most_similar_crown)}\")\n",
    "print(f\"Right ==> Teeth3DS Similar Jaw's Tooth of same FDI Label as abutment: {os.path.basename(abutment_teeth_most_similar_jaw_filename)}\")\n",
    "\n",
    "print(dice_score)\n",
    "print(similarity_score)\n",
    "\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600efdae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
